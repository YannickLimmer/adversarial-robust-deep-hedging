{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c547934a-0644-4864-9a08-b0f269764f37",
   "metadata": {},
   "source": [
    "# Adversarial Robust Deep Hedging\n",
    "#### Exploring the Black-Scholes Model\n",
    "(Example 7.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c30c9d-2c72-4613-b78e-1c581ba4e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "from src.deep_hedging.DeepHedge import DeepHedgeConfig, DeepHedge\n",
    "from src.deep_hedging.DeepHedgeTrainer import DeepHedgeTrainer, DeepHedgeTrainerConfig\n",
    "from src.deep_hedging.StrategyNet import StrategyNetConfig\n",
    "from src.deep_hedging.objectives.HedgeObjective import MeanVariance, Entropy, StableEntropy\n",
    "from src.derivative.EuropeanCallOption import EuropeanCallOption\n",
    "from src.gan.RobustDhGan import RobustDhGan\n",
    "from src.generator.BlackScholesCoefficient import BlackScholesCoefficientConfig, BlackScholesDriftCoefficient, BlackScholesDiffusionCoefficient\n",
    "from src.generator.SdeGenerator import GeneratorConfig, SdeGenerator\n",
    "from src.util.processes.BlackScholesGenerator import BlackScholesGenerator\n",
    "from src.generator.SdeGeneratorTrainer import SdeGeneratorTrainerConfig\n",
    "from src.penalty.Augmentations import LeadLag, AddTimeComponent\n",
    "from src.penalty.SigWassersteinMetric import SignatureConfig, SigWassersteinMetric\n",
    "from src.penalty.CompareVolatility import CompareVolatility, VolatilityComparisonConfig\n",
    "from src.util.TimeUtil import UniformTimeDiscretization\n",
    "from src.util.processes.BlackScholesGenerator import BlackScholesParameterSet, BlackScholesGenerator\n",
    "from src.util.processes.BrownianMotionGenerator import BrownianMotionGenerator\n",
    "from src.util.processes.HestonGenerator import HestonParameterSet, HestonGenerator\n",
    "from src.util.torch_util.AdapterUtil import Adapter, AdapterList, SelectDimensions, ConvertToIncrements\n",
    "from src.util.torch_util.TrainingUtil import TrainerConfig\n",
    "from src.util.torch_util.CallbackUtil import PrintMetrics, PrintGeneratorParameters, PrintEmptyLine\n",
    "from src.util.VisualizationUtil import QuantityLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63008ad9-cc38-468c-a519-8019d87136e2",
   "metadata": {},
   "source": [
    "## Initialize\n",
    "\n",
    "### Reference model and generator \n",
    "\n",
    "We begin by initializing the true market model. We choose the following paramters for demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1992fa58-2f89-4468-a3ff-a76af7318b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_parameters = BlackScholesParameterSet(drift=0.0, sigma=0.2)\n",
    "initial_asset_price = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e802ab-efb0-4d18-af48-a891ae0ecb29",
   "metadata": {},
   "source": [
    "Moreover, we need the following market parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7384ddfd-0549-4562-83d3-c33f2b6042ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_freq: int = 5\n",
    "td = UniformTimeDiscretization(trading_freq * 1. / 255., 90 // trading_freq)\n",
    "derivative = EuropeanCallOption(strike=1.0, time_discretization=td, price=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f7bcd4-d244-46f3-9516-2d9e933ad83e",
   "metadata": {},
   "source": [
    "This allows us to define a generator for the true underlying model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0554433-e4c9-4257-a32c-2b1f2e9394a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_generator = BlackScholesGenerator(\n",
    "    drift=np.array([bs_parameters.drift]),\n",
    "    sigma=np.array([bs_parameters.sigma]),\n",
    ").provide_generator(\n",
    "    initial_value=np.array([initial_asset_price]),\n",
    "    times=td.times,\n",
    "    random_number_generator=np.random.default_rng(1111),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edc42e4-dda0-4c4c-9513-a6c2fc3b7d5e",
   "metadata": {},
   "source": [
    "### Generate small data environments\n",
    "\n",
    "We now generate `number_of_scenarios` scenarios, where we only few paths from the reference model given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f018c211-e8fb-4409-880e-085bdf88a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_scenarios = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5939994-54b6-4aa5-8f33-21ba046b06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [reference_generator(30) for _ in range(number_of_scenarios)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295495aa-bd61-4bfb-b404-c66a4cde602a",
   "metadata": {},
   "source": [
    "### Define corresponding penalties\n",
    "\n",
    "We can now initialize penalties that determine the distance to the generated paths in each scenario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af1ccf50-98e1-43f6-85a2-2d9a877c3130",
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_config = VolatilityComparisonConfig(td)\n",
    "penalizers = [\n",
    "    CompareVolatility(scenario, pen_config, transform=lambda x: 0.8 * x) for scenario in scenarios\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04ffb7-cb64-4516-a44a-af3ea04ccd96",
   "metadata": {},
   "source": [
    "They measure the distance of generated paths by considering the distance to the heuristic volatility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e8378d-219c-4451-a0ce-3a07363ec7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "volatilities_for_scenarios = [torch.mean(pen.original_volatility).item() for pen in penalizers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea853909-ffc0-4515-b5de-27737782f206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(5,3))\n",
    "axs.hist(volatilities_for_scenarios, bins=41)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd00a6c-b90b-472d-a615-2f5948789991",
   "metadata": {},
   "source": [
    "### Initialize generators\n",
    "\n",
    "With this, we can now initialize an `SdeGenerator` that has `BlackScholesCoefficient` corresponding to the above estimates. \n",
    "\n",
    "Note that formally these would be calibrated to the data in this step, but we omit this, since the result is obviously equivalent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23751f11-f14d-4336-81c2-d863b5608d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "generators = []\n",
    "for vol in volatilities_for_scenarios:\n",
    "    coef_config = BlackScholesCoefficientConfig(\n",
    "        BlackScholesParameterSet(drift=bs_parameters.drift, sigma=vol),\n",
    "        initial_asset_price=1.0,\n",
    "    )\n",
    "    drift_coef, diffusion_coef = BlackScholesDriftCoefficient(coef_config), BlackScholesDiffusionCoefficient(coef_config)\n",
    "    gen_config = GeneratorConfig(td, drift_coef.get_initial_asset_price, drift_coef, diffusion_coef)\n",
    "    generators.append(SdeGenerator(generator_config=gen_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ddc06-59d2-44ee-8dc7-ba03219e19b4",
   "metadata": {},
   "source": [
    "We disable the training for all drift parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c11757de-9934-4da1-a3aa-bb8477b2598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in generators:\n",
    "    g.drift.drift.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42851e82-3d35-4686-a8ff-687c650e7287",
   "metadata": {},
   "source": [
    "### Noise Generator\n",
    "In order to utilize the generator, we require a noise generator. In this case, this is a simple Brownian motion generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54eaa055-b629-4295-94df-bd0eb469ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_generator = BrownianMotionGenerator().provide_increment_generator(\n",
    "    initial_value=np.zeros(1),\n",
    "    times=td.times,\n",
    "    random_number_generator=np.random.default_rng(4444),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d895e-1b59-4764-b5c2-ed89ad79fdad",
   "metadata": {},
   "source": [
    "We can now verify that the generators are initialized accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f296c1a-a3bf-4b2b-a371-642a8c752e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization_errors = [p(g(noise_generator(1000))).item() for g, p in tqdm(zip(generators, penalizers), total=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d8f41cf-321d-4d21-9240-709ad9727678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1, 1, figsize=(5,3))\n",
    "# axs.hist(initialization_errors, bins=41)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502c7231-0c23-4183-a52e-0e85812f6d40",
   "metadata": {},
   "source": [
    "## Deep Hedging\n",
    "\n",
    "We will now train a deep hedge on each of the individual models. This has tow purposes\n",
    "\n",
    "1. we use these deep hedges as pre-trained components for the actual application of the robust hedge GAN, and\n",
    "2. we will use these hedges to compare the robust hedge GAN on out-of-sample generated data against."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af48580-152e-43cb-8495-0a9db3fa13fd",
   "metadata": {},
   "source": [
    "### Initialization \n",
    "\n",
    "We begin by setting a hedging objective, since it remains the same over all models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "128a725e-f74e-48c0-beab-a55329293ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hedge_objective = MeanVariance(84)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6678946-92a7-4cb8-a68e-07cf363bef08",
   "metadata": {},
   "source": [
    "Next, we define the deep hedges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58cb1d64-de79-4de6-9a1e-20b9c3c3d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_hedges = []\n",
    "for g in generators:\n",
    "    strategy_config = StrategyNetConfig(dimension_of_asset=1, number_of_layers=3, nodes_in_intermediate_layers=36)\n",
    "    initial_asset_price_for_deep_hedge = torch.tensor([initial_asset_price], dtype=torch.float32)\n",
    "    deep_hedges.append(DeepHedge(DeepHedgeConfig(derivative, initial_asset_price_for_deep_hedge, strategy_config)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be13609e-e17a-4bad-b496-7f944e3f3a44",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We will now train each individual hedge on the corresponding generator. For this we will use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ee1874d-d095-4f23-977c-5c9b4724a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50000\n",
    "batch_sizes_for_epoch = [100]*2 + [1000]*2 + [10000]*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b06443e6-a38b-4cbc-a6cb-ae8e797eee14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2796eda0b26244f69ce3b7b1b8e11a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses_for_scenarios = []\n",
    "\n",
    "for i, dh in tqdm(enumerate(deep_hedges), total=number_of_scenarios):\n",
    "    \n",
    "    try:\n",
    "        dh.load_state_dict(torch.load(f'resources/network-states/bs_test/scenario_{i}.pt'))\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        dh.train()\n",
    "\n",
    "        generated = ConvertToIncrements()(generators[i](noise_generator(sample_size)).detach())\n",
    "        opt = torch.optim.Adam(dh.parameters())\n",
    "\n",
    "        losses = QuantityLogger()\n",
    "        bbar = tqdm(batch_sizes_for_epoch, leave=False)\n",
    "        for batch_size in bbar:\n",
    "            losses.set_mark()\n",
    "            pbar = tqdm(\n",
    "                [generated[bno:min(bno + batch_size, sample_size)] for bno in range(0, sample_size, batch_size)],\n",
    "                leave=False,\n",
    "            )\n",
    "            for batch in pbar:\n",
    "                pnl = dh(batch)\n",
    "                loss = hedge_objective(pnl)\n",
    "                dh.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                losses.update(loss.item())\n",
    "                pbar.set_postfix({'Loss': losses.average_since_mark})\n",
    "\n",
    "            bbar.set_postfix({'Loss': losses.average_since_mark})\n",
    "\n",
    "        torch.save(dh.state_dict(), f'resources/network-states/bs_test/scenario_{i}.pt') \n",
    "        losses_for_scenarios.append(losses)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebb80ae3-2ac6-45a6-8f86-2cb8028dff60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.load('resources/network-states/bs_test/losses.npz', allow_pickle=True)['scenario_0'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee985476-7414-44f2-8a91-fe3973c3ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe loss curves\n",
    "losses_dict = {f'scenario_{i}': np.array(l.history) for i, l in enumerate(losses_for_scenarios)}\n",
    "np.savez('resources/network-states/bs_test/losses.npz', **losses_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2a1f4b-52f2-466e-9fe5-8eb9968f959b",
   "metadata": {},
   "source": [
    "### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d3c1bbd1-d02e-486b-b7bf-0288abe537ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (We initialize the reference generator to reset the RNG)\n",
    "reference_generator = BlackScholesGenerator(\n",
    "    drift=np.array([bs_parameters.drift]),\n",
    "    sigma=np.array([bs_parameters.sigma]),\n",
    ").provide_generator(\n",
    "    initial_value=np.array([initial_asset_price]),\n",
    "    times=td.times,\n",
    "    random_number_generator=np.random.default_rng(1111),\n",
    ")\n",
    "test_data = torch.diff(reference_generator(10000), 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "02ca2985-93f4-4f44-bdb5-5375e02739d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "deep_hedges[0].eval()\n",
    "deep_hedge_results = np.sum(deep_hedges[0](test_data).detach().numpy() * test_data.numpy(), axis=(1, 2))\n",
    "terminal_values_on_test = np.sum(test_data.numpy(), axis=1)[:, 0] + 1.0\n",
    "plt.scatter(terminal_values_on_test, deep_hedge_results, s=.1)\n",
    "deep_hedges[0].train()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f89e5785-8f18-46d1-9c0e-8feed8726e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92cb3c5716ab44329d0b3d41a7845a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oosp = [hedge_objective(dh(test_data)).item() for dh in tqdm(deep_hedges)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32e28eb6-dfbc-4482-8819-145d7ef96ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(oosp, bins=21)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4249b7eb-e238-4d26-9ea0-e9c6ab868690",
   "metadata": {},
   "source": [
    "### Robust Hedge GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e5f48fb-9117-4864-a657-1ebaf5aa8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_dh_gans = []\n",
    "for dh, p, g in zip(deep_hedges, penalizers, generators):\n",
    "    g_opt = torch.optim.Adam(g.parameters())\n",
    "    gen_adapters = AdapterList([])\n",
    "    gen_train_config = SdeGeneratorTrainerConfig(g, p, g_opt, gen_adapters)\n",
    "    \n",
    "    h_opt = torch.optim.Adam(dh.parameters())\n",
    "    hedge_adapters = AdapterList([ConvertToIncrements()])\n",
    "    dh_train_config = DeepHedgeTrainerConfig(dh, hedge_objective, h_opt, hedge_adapters)\n",
    "\n",
    "    robust_dh_gans.append(RobustDhGan(\n",
    "        hedge_config=dh_train_config,\n",
    "        gen_config=gen_train_config,\n",
    "        trainer_config=TrainerConfig(1000, 100000, noise_generator, 1),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9d499d-ee4f-4139-9f21-555fef50a310",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00c0e20d-c349-472c-8af7-c9d95da079b6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65ec976aedb432182ccdec6c69a148b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1  \tH-Loss:  0.063174    G-Loss: -0.056957    Penlty:  0.006217\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242224\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052125    G-Loss: -0.045238    Penlty:  0.006887\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.201777\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061840    G-Loss: -0.054577    Penlty:  0.007263\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237480\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061103    G-Loss: -0.048659    Penlty:  0.012444\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237422\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057634    G-Loss: -0.047567    Penlty:  0.010068\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222283\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061546    G-Loss: -0.053743    Penlty:  0.007803\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.235777\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059289    G-Loss: -0.051978    Penlty:  0.007310\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231509\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048537    G-Loss: -0.040703    Penlty:  0.007835\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.193624\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054072    G-Loss: -0.047472    Penlty:  0.006600\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.209157\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056741    G-Loss: -0.050044    Penlty:  0.006697\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214902\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054780    G-Loss: -0.046419    Penlty:  0.008361\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213259\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.066327    G-Loss: -0.057313    Penlty:  0.009014\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.245832\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065035    G-Loss: -0.054890    Penlty:  0.010145\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.247865\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053921    G-Loss: -0.047873    Penlty:  0.006048\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211806\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060884    G-Loss: -0.054821    Penlty:  0.006063\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.235379\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.046172    G-Loss: -0.040710    Penlty:  0.005461\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.182383\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057303    G-Loss: -0.044690    Penlty:  0.012613\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231696\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051069    G-Loss: -0.045357    Penlty:  0.005712\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.194758\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054343    G-Loss: -0.047458    Penlty:  0.006885\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212593\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057089    G-Loss: -0.048090    Penlty:  0.008999\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225540\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060821    G-Loss: -0.051355    Penlty:  0.009466\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234941\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057587    G-Loss: -0.051781    Penlty:  0.005806\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218436\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055373    G-Loss: -0.048621    Penlty:  0.006753\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210071\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054403    G-Loss: -0.047503    Penlty:  0.006900\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211697\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058679    G-Loss: -0.052385    Penlty:  0.006294\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226577\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052350    G-Loss: -0.044132    Penlty:  0.008218\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202417\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053509    G-Loss: -0.040781    Penlty:  0.012728\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222100\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056319    G-Loss: -0.050811    Penlty:  0.005508\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217421\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051996    G-Loss: -0.046457    Penlty:  0.005539\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.203563\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059577    G-Loss: -0.053568    Penlty:  0.006010\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228841\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054671    G-Loss: -0.043626    Penlty:  0.011046\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.220556\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056554    G-Loss: -0.049118    Penlty:  0.007436\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216415\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056753    G-Loss: -0.052025    Penlty:  0.004728\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219445\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.067905    G-Loss: -0.061661    Penlty:  0.006244\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.257574\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053032    G-Loss: -0.047136    Penlty:  0.005896\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202876\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065937    G-Loss: -0.057167    Penlty:  0.008771\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.250868\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060687    G-Loss: -0.053411    Penlty:  0.007276\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.232947\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060896    G-Loss: -0.054331    Penlty:  0.006565\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231025\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057745    G-Loss: -0.052384    Penlty:  0.005361\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221600\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057397    G-Loss: -0.050237    Penlty:  0.007160\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.220693\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054653    G-Loss: -0.047944    Penlty:  0.006709\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211320\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059889    G-Loss: -0.052316    Penlty:  0.007573\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231418\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062695    G-Loss: -0.055609    Penlty:  0.007086\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242806\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061070    G-Loss: -0.051970    Penlty:  0.009100\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228752\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061345    G-Loss: -0.053670    Penlty:  0.007675\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237242\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055818    G-Loss: -0.049511    Penlty:  0.006307\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215065\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054468    G-Loss: -0.046321    Penlty:  0.008147\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214546\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060728    G-Loss: -0.053478    Penlty:  0.007250\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234379\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053578    G-Loss: -0.045224    Penlty:  0.008354\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211131\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.047815    G-Loss: -0.042377    Penlty:  0.005438\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.185641\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056105    G-Loss: -0.051900    Penlty:  0.004205\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215452\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057131    G-Loss: -0.049719    Penlty:  0.007412\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215638\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052881    G-Loss: -0.048554    Penlty:  0.004328\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200609\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058179    G-Loss: -0.048049    Penlty:  0.010130\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227020\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057586    G-Loss: -0.050663    Penlty:  0.006924\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.220574\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051793    G-Loss: -0.042407    Penlty:  0.009386\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213237\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061354    G-Loss: -0.053003    Penlty:  0.008351\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234286\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059710    G-Loss: -0.053767    Penlty:  0.005944\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.230137\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056637    G-Loss: -0.048651    Penlty:  0.007986\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214543\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062812    G-Loss: -0.055458    Penlty:  0.007354\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.241010\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054804    G-Loss: -0.048679    Penlty:  0.006125\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211922\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062562    G-Loss: -0.054576    Penlty:  0.007986\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.235810\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054393    G-Loss: -0.046466    Penlty:  0.007927\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213860\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062667    G-Loss: -0.054660    Penlty:  0.008007\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242682\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050026    G-Loss: -0.041448    Penlty:  0.008579\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198915\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053052    G-Loss: -0.045852    Penlty:  0.007201\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.204989\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059977    G-Loss: -0.053446    Penlty:  0.006531\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229757\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063731    G-Loss: -0.054134    Penlty:  0.009597\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231079\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056811    G-Loss: -0.050131    Penlty:  0.006680\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.220382\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059390    G-Loss: -0.054047    Penlty:  0.005342\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228724\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057286    G-Loss: -0.048643    Penlty:  0.008643\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221655\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.046272    G-Loss: -0.040691    Penlty:  0.005581\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.182303\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057083    G-Loss: -0.042408    Penlty:  0.014676\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236510\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049661    G-Loss: -0.043043    Penlty:  0.006618\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.196515\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059142    G-Loss: -0.053726    Penlty:  0.005416\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227533\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055822    G-Loss: -0.050530    Penlty:  0.005293\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216298\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053213    G-Loss: -0.045073    Penlty:  0.008139\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.207678\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060614    G-Loss: -0.049229    Penlty:  0.011385\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236806\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060458    G-Loss: -0.049431    Penlty:  0.011028\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237637\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052608    G-Loss: -0.045702    Penlty:  0.006907\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.203934\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059013    G-Loss: -0.051171    Penlty:  0.007842\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.230482\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055518    G-Loss: -0.045059    Penlty:  0.010459\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219582\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058460    G-Loss: -0.048046    Penlty:  0.010414\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.230393\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051988    G-Loss: -0.046519    Penlty:  0.005469\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.203221\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055798    G-Loss: -0.043986    Penlty:  0.011813\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221499\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049939    G-Loss: -0.044869    Penlty:  0.005070\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.189164\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060404    G-Loss: -0.049978    Penlty:  0.010425\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229814\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054708    G-Loss: -0.049744    Penlty:  0.004965\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212700\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060597    G-Loss: -0.051700    Penlty:  0.008897\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229979\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057004    G-Loss: -0.049452    Penlty:  0.007552\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221404\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051741    G-Loss: -0.045303    Penlty:  0.006438\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.203357\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054001    G-Loss: -0.048421    Penlty:  0.005580\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206820\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058330    G-Loss: -0.051763    Penlty:  0.006566\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223952\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.068053    G-Loss: -0.060672    Penlty:  0.007380\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.256851\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054937    G-Loss: -0.048179    Penlty:  0.006758\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214641\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050075    G-Loss: -0.044229    Penlty:  0.005846\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.195197\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055298    G-Loss: -0.050121    Penlty:  0.005177\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214936\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055543    G-Loss: -0.049875    Penlty:  0.005668\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210433\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051037    G-Loss: -0.045223    Penlty:  0.005814\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.196667\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058798    G-Loss: -0.047661    Penlty:  0.011137\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231172\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057501    G-Loss: -0.052150    Penlty:  0.005351\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221313\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048798    G-Loss: -0.040739    Penlty:  0.008060\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.192615\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061586    G-Loss: -0.053714    Penlty:  0.007872\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236114\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050726    G-Loss: -0.044219    Penlty:  0.006507\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198442\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061595    G-Loss: -0.052042    Penlty:  0.009553\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.232313\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054011    G-Loss: -0.042414    Penlty:  0.011597\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221097\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.068562    G-Loss: -0.058262    Penlty:  0.010300\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.262404\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056578    G-Loss: -0.048973    Penlty:  0.007605\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217660\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058725    G-Loss: -0.047625    Penlty:  0.011100\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231375\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051153    G-Loss: -0.044959    Penlty:  0.006195\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.197765\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058254    G-Loss: -0.052882    Penlty:  0.005371\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224261\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052923    G-Loss: -0.046752    Penlty:  0.006171\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.204006\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048855    G-Loss: -0.042567    Penlty:  0.006288\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.192569\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054626    G-Loss: -0.048810    Penlty:  0.005816\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210630\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050983    G-Loss: -0.044207    Penlty:  0.006775\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198678\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057968    G-Loss: -0.052962    Penlty:  0.005006\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224818\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055850    G-Loss: -0.050528    Penlty:  0.005322\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219273\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064881    G-Loss: -0.059446    Penlty:  0.005434\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.247719\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059474    G-Loss: -0.049835    Penlty:  0.009639\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233556\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060578    G-Loss: -0.053861    Penlty:  0.006718\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233043\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050558    G-Loss: -0.045504    Penlty:  0.005055\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198792\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058054    G-Loss: -0.051064    Penlty:  0.006990\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223349\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056585    G-Loss: -0.045339    Penlty:  0.011246\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223914\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055728    G-Loss: -0.050266    Penlty:  0.005462\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210936\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051628    G-Loss: -0.044472    Penlty:  0.007156\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.204033\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054167    G-Loss: -0.047156    Penlty:  0.007010\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210071\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063950    G-Loss: -0.056005    Penlty:  0.007944\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.245772\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057937    G-Loss: -0.053868    Penlty:  0.004069\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219636\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053782    G-Loss: -0.047424    Penlty:  0.006359\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206601\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.070477    G-Loss: -0.062070    Penlty:  0.008407\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.265606\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057809    G-Loss: -0.051282    Penlty:  0.006527\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218613\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058751    G-Loss: -0.052392    Penlty:  0.006359\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226720\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052649    G-Loss: -0.046198    Penlty:  0.006451\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.204609\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063383    G-Loss: -0.056929    Penlty:  0.006454\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.239783\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052061    G-Loss: -0.045241    Penlty:  0.006820\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202323\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059308    G-Loss: -0.054594    Penlty:  0.004714\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228311\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058623    G-Loss: -0.050040    Penlty:  0.008583\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224658\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062595    G-Loss: -0.056997    Penlty:  0.005598\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234013\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065076    G-Loss: -0.059110    Penlty:  0.005966\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.248490\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053599    G-Loss: -0.043663    Penlty:  0.009936\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210986\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057865    G-Loss: -0.049609    Penlty:  0.008257\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224462\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055636    G-Loss: -0.044913    Penlty:  0.010722\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225666\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.069447    G-Loss: -0.063037    Penlty:  0.006410\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.263695\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058051    G-Loss: -0.048886    Penlty:  0.009165\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225974\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053877    G-Loss: -0.045651    Penlty:  0.008227\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212290\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058487    G-Loss: -0.051696    Penlty:  0.006792\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225206\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061286    G-Loss: -0.056520    Penlty:  0.004765\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224471\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059546    G-Loss: -0.047469    Penlty:  0.012077\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234372\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053550    G-Loss: -0.046369    Penlty:  0.007182\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.208567\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050926    G-Loss: -0.043814    Penlty:  0.007112\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198116\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058742    G-Loss: -0.050919    Penlty:  0.007823\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223796\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063058    G-Loss: -0.053315    Penlty:  0.009743\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.244082\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055248    G-Loss: -0.048603    Penlty:  0.006645\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.208946\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053061    G-Loss: -0.047280    Penlty:  0.005781\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206384\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062445    G-Loss: -0.055879    Penlty:  0.006566\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236776\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061572    G-Loss: -0.054471    Penlty:  0.007101\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.235261\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054650    G-Loss: -0.047573    Penlty:  0.007077\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212940\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052599    G-Loss: -0.046848    Penlty:  0.005751\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206163\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065656    G-Loss: -0.057328    Penlty:  0.008328\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.249734\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063953    G-Loss: -0.055475    Penlty:  0.008478\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242868\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053766    G-Loss: -0.047986    Penlty:  0.005780\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205233\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053397    G-Loss: -0.048892    Penlty:  0.004505\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.207702\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055892    G-Loss: -0.049690    Penlty:  0.006202\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216072\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054511    G-Loss: -0.045346    Penlty:  0.009165\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219883\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059195    G-Loss: -0.052855    Penlty:  0.006340\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226531\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051947    G-Loss: -0.047778    Penlty:  0.004169\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.197657\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.066727    G-Loss: -0.056031    Penlty:  0.010696\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.257397\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058028    G-Loss: -0.051579    Penlty:  0.006448\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224384\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054534    G-Loss: -0.046042    Penlty:  0.008491\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213570\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059087    G-Loss: -0.053780    Penlty:  0.005306\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228433\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060321    G-Loss: -0.050257    Penlty:  0.010063\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.235482\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059769    G-Loss: -0.049483    Penlty:  0.010286\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233182\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059235    G-Loss: -0.053906    Penlty:  0.005328\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222929\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058558    G-Loss: -0.049958    Penlty:  0.008600\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228652\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055967    G-Loss: -0.047302    Penlty:  0.008665\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218970\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057860    G-Loss: -0.051583    Penlty:  0.006277\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222345\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057500    G-Loss: -0.049673    Penlty:  0.007827\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221567\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059306    G-Loss: -0.051299    Penlty:  0.008006\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229728\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055307    G-Loss: -0.048945    Penlty:  0.006362\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212197\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065415    G-Loss: -0.055061    Penlty:  0.010354\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.252522\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053147    G-Loss: -0.041817    Penlty:  0.011330\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213452\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063486    G-Loss: -0.056738    Penlty:  0.006748\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242138\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056429    G-Loss: -0.045751    Penlty:  0.010678\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224196\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057193    G-Loss: -0.047789    Penlty:  0.009404\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221994\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051647    G-Loss: -0.045837    Penlty:  0.005810\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202663\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057631    G-Loss: -0.052410    Penlty:  0.005221\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222514\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061075    G-Loss: -0.054105    Penlty:  0.006970\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.232473\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060946    G-Loss: -0.053667    Penlty:  0.007279\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.235295\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052586    G-Loss: -0.043513    Penlty:  0.009073\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210953\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051961    G-Loss: -0.047739    Penlty:  0.004222\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202208\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064344    G-Loss: -0.055344    Penlty:  0.009000\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242077\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052040    G-Loss: -0.047534    Penlty:  0.004506\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200748\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062698    G-Loss: -0.048635    Penlty:  0.014062\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.241547\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050458    G-Loss: -0.046725    Penlty:  0.003733\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.196662\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058693    G-Loss: -0.045444    Penlty:  0.013248\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.235162\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053686    G-Loss: -0.048655    Penlty:  0.005031\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.204841\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055144    G-Loss: -0.050181    Penlty:  0.004964\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213355\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060609    G-Loss: -0.055250    Penlty:  0.005360\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228345\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051418    G-Loss: -0.045179    Penlty:  0.006238\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.201326\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048432    G-Loss: -0.044129    Penlty:  0.004303\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.189067\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055070    G-Loss: -0.047383    Penlty:  0.007687\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215388\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054741    G-Loss: -0.045315    Penlty:  0.009426\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215521\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.067589    G-Loss: -0.059468    Penlty:  0.008122\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.257716\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061224    G-Loss: -0.052623    Penlty:  0.008601\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234314\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053538    G-Loss: -0.047406    Penlty:  0.006132\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.207529\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064223    G-Loss: -0.055737    Penlty:  0.008486\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.245220\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.047175    G-Loss: -0.043747    Penlty:  0.003429\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.184919\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051791    G-Loss: -0.045982    Penlty:  0.005808\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200568\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.066140    G-Loss: -0.059895    Penlty:  0.006245\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.253622\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056785    G-Loss: -0.049976    Penlty:  0.006809\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.220916\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064659    G-Loss: -0.056608    Penlty:  0.008050\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.247152\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065128    G-Loss: -0.054984    Penlty:  0.010144\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.249717\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054964    G-Loss: -0.048912    Penlty:  0.006052\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212805\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053675    G-Loss: -0.048946    Penlty:  0.004729\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210726\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053203    G-Loss: -0.047179    Penlty:  0.006024\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206240\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048149    G-Loss: -0.042792    Penlty:  0.005357\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.188256\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060837    G-Loss: -0.053637    Penlty:  0.007200\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.232564\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061642    G-Loss: -0.056884    Penlty:  0.004758\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238615\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055075    G-Loss: -0.049273    Penlty:  0.005802\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214562\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052803    G-Loss: -0.046710    Penlty:  0.006092\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202409\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.044432    G-Loss: -0.037501    Penlty:  0.006931\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.182171\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058289    G-Loss: -0.050819    Penlty:  0.007469\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226090\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060549    G-Loss: -0.050835    Penlty:  0.009714\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236560\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060936    G-Loss: -0.053217    Penlty:  0.007719\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233137\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059707    G-Loss: -0.053399    Penlty:  0.006308\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225596\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051106    G-Loss: -0.043933    Penlty:  0.007173\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202123\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065998    G-Loss: -0.055845    Penlty:  0.010153\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.254549\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057135    G-Loss: -0.050092    Penlty:  0.007043\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.220789\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048045    G-Loss: -0.040678    Penlty:  0.007367\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.187778\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054744    G-Loss: -0.048001    Penlty:  0.006742\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.208179\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060424    G-Loss: -0.053511    Penlty:  0.006913\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228649\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056719    G-Loss: -0.050551    Penlty:  0.006168\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218508\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051581    G-Loss: -0.043447    Penlty:  0.008134\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.204961\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055324    G-Loss: -0.046842    Penlty:  0.008482\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213068\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059305    G-Loss: -0.053405    Penlty:  0.005901\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225462\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054055    G-Loss: -0.045567    Penlty:  0.008489\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.208489\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053693    G-Loss: -0.042674    Penlty:  0.011019\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.220581\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051832    G-Loss: -0.045326    Penlty:  0.006506\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200623\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050992    G-Loss: -0.043586    Penlty:  0.007406\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200183\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056263    G-Loss: -0.047941    Penlty:  0.008322\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218413\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059771    G-Loss: -0.048703    Penlty:  0.011068\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234795\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062260    G-Loss: -0.053287    Penlty:  0.008973\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229927\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059504    G-Loss: -0.054226    Penlty:  0.005278\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224861\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048611    G-Loss: -0.042900    Penlty:  0.005711\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.188920\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063994    G-Loss: -0.057342    Penlty:  0.006652\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.244781\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048827    G-Loss: -0.040294    Penlty:  0.008534\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.191925\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059771    G-Loss: -0.048596    Penlty:  0.011175\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.230855\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065543    G-Loss: -0.056870    Penlty:  0.008673\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.252458\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056188    G-Loss: -0.044378    Penlty:  0.011810\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228738\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.066418    G-Loss: -0.054486    Penlty:  0.011932\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.258513\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053671    G-Loss: -0.048337    Penlty:  0.005334\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205928\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057566    G-Loss: -0.049429    Penlty:  0.008137\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222329\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060983    G-Loss: -0.052346    Penlty:  0.008637\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226290\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052621    G-Loss: -0.048007    Penlty:  0.004614\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202967\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059965    G-Loss: -0.051562    Penlty:  0.008403\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233442\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054846    G-Loss: -0.045165    Penlty:  0.009682\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217175\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064781    G-Loss: -0.057636    Penlty:  0.007145\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226201\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056680    G-Loss: -0.046904    Penlty:  0.009776\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221372\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048702    G-Loss: -0.042719    Penlty:  0.005983\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.192001\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062946    G-Loss: -0.055226    Penlty:  0.007720\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234927\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064468    G-Loss: -0.056465    Penlty:  0.008002\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.245393\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057025    G-Loss: -0.047170    Penlty:  0.009856\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224297\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056324    G-Loss: -0.047889    Penlty:  0.008434\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218714\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064977    G-Loss: -0.057226    Penlty:  0.007751\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.247501\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065879    G-Loss: -0.058177    Penlty:  0.007702\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.246968\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052859    G-Loss: -0.047503    Penlty:  0.005356\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205597\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058121    G-Loss: -0.052944    Penlty:  0.005176\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223000\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059224    G-Loss: -0.053551    Penlty:  0.005673\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227746\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.066017    G-Loss: -0.057887    Penlty:  0.008129\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.253172\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058531    G-Loss: -0.050485    Penlty:  0.008046\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223692\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053813    G-Loss: -0.048011    Penlty:  0.005803\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206620\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054780    G-Loss: -0.046083    Penlty:  0.008697\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215834\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061392    G-Loss: -0.054159    Penlty:  0.007233\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.235538\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056645    G-Loss: -0.042454    Penlty:  0.014191\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231290\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062147    G-Loss: -0.051751    Penlty:  0.010396\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.240119\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062504    G-Loss: -0.056783    Penlty:  0.005720\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236713\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051036    G-Loss: -0.044399    Penlty:  0.006637\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.194866\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056870    G-Loss: -0.052076    Penlty:  0.004795\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217958\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055173    G-Loss: -0.048533    Penlty:  0.006639\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.209867\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052186    G-Loss: -0.044363    Penlty:  0.007823\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205821\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055194    G-Loss: -0.046728    Penlty:  0.008466\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214684\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058254    G-Loss: -0.051319    Penlty:  0.006935\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225069\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058671    G-Loss: -0.050161    Penlty:  0.008510\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225550\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058149    G-Loss: -0.049465    Penlty:  0.008685\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224343\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059140    G-Loss: -0.050764    Penlty:  0.008376\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226106\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058834    G-Loss: -0.045977    Penlty:  0.012857\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238487\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065352    G-Loss: -0.053771    Penlty:  0.011581\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.253230\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062986    G-Loss: -0.052951    Penlty:  0.010035\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238634\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062143    G-Loss: -0.053142    Penlty:  0.009001\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236748\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.066874    G-Loss: -0.058440    Penlty:  0.008434\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.255933\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055596    G-Loss: -0.047311    Penlty:  0.008286\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214905\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060193    G-Loss: -0.053412    Penlty:  0.006781\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229211\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.067700    G-Loss: -0.057974    Penlty:  0.009726\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.260820\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058474    G-Loss: -0.051144    Penlty:  0.007330\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223678\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054252    G-Loss: -0.047865    Penlty:  0.006386\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.207076\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062897    G-Loss: -0.053262    Penlty:  0.009634\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238868\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063744    G-Loss: -0.054496    Penlty:  0.009248\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242190\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056447    G-Loss: -0.049229    Penlty:  0.007218\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217934\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063820    G-Loss: -0.056722    Penlty:  0.007099\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238872\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057836    G-Loss: -0.050349    Penlty:  0.007487\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222898\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063580    G-Loss: -0.054925    Penlty:  0.008655\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.247726\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058724    G-Loss: -0.052120    Penlty:  0.006604\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227395\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058582    G-Loss: -0.051900    Penlty:  0.006683\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227682\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058093    G-Loss: -0.051885    Penlty:  0.006208\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224396\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063646    G-Loss: -0.050973    Penlty:  0.012674\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.252288\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050271    G-Loss: -0.043771    Penlty:  0.006500\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.197567\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.069115    G-Loss: -0.059972    Penlty:  0.009143\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.263904\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059107    G-Loss: -0.052508    Penlty:  0.006599\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.230085\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057088    G-Loss: -0.050189    Penlty:  0.006899\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221953\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061800    G-Loss: -0.055582    Penlty:  0.006218\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231581\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058628    G-Loss: -0.050032    Penlty:  0.008596\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227085\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055430    G-Loss: -0.049882    Penlty:  0.005548\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211697\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061020    G-Loss: -0.050509    Penlty:  0.010511\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236398\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052604    G-Loss: -0.043455    Penlty:  0.009149\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.209698\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.068343    G-Loss: -0.056169    Penlty:  0.012174\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.264191\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049181    G-Loss: -0.041721    Penlty:  0.007461\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.193677\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063948    G-Loss: -0.053748    Penlty:  0.010200\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.245792\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054473    G-Loss: -0.043399    Penlty:  0.011074\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222719\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062891    G-Loss: -0.056857    Penlty:  0.006034\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.241446\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.044804    G-Loss: -0.039215    Penlty:  0.005588\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.177116\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056962    G-Loss: -0.051157    Penlty:  0.005806\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217239\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057247    G-Loss: -0.049197    Penlty:  0.008049\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219854\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055130    G-Loss: -0.045217    Penlty:  0.009913\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219163\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056031    G-Loss: -0.045594    Penlty:  0.010437\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217272\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.071400    G-Loss: -0.061355    Penlty:  0.010045\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.275072\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062657    G-Loss: -0.056929    Penlty:  0.005727\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237657\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.046331    G-Loss: -0.039753    Penlty:  0.006578\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.183620\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056394    G-Loss: -0.050318    Penlty:  0.006076\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217330\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053550    G-Loss: -0.046915    Penlty:  0.006635\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.209557\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060580    G-Loss: -0.054305    Penlty:  0.006275\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228778\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056260    G-Loss: -0.048816    Penlty:  0.007444\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217819\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056200    G-Loss: -0.049643    Penlty:  0.006557\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217158\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056718    G-Loss: -0.049949    Penlty:  0.006768\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217764\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064313    G-Loss: -0.056635    Penlty:  0.007678\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.247132\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056282    G-Loss: -0.050010    Penlty:  0.006272\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218986\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060836    G-Loss: -0.053116    Penlty:  0.007720\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233227\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058856    G-Loss: -0.053061    Penlty:  0.005795\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225063\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053491    G-Loss: -0.049541    Penlty:  0.003950\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206654\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058707    G-Loss: -0.048668    Penlty:  0.010039\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227480\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056448    G-Loss: -0.049198    Penlty:  0.007250\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216523\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049381    G-Loss: -0.041679    Penlty:  0.007702\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.197251\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048142    G-Loss: -0.040223    Penlty:  0.007919\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.192260\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058031    G-Loss: -0.049404    Penlty:  0.008627\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213270\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051371    G-Loss: -0.046459    Penlty:  0.004912\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.197774\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052219    G-Loss: -0.043527    Penlty:  0.008691\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211715\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052058    G-Loss: -0.045022    Penlty:  0.007036\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.204919\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059029    G-Loss: -0.048629    Penlty:  0.010399\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221756\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057683    G-Loss: -0.049043    Penlty:  0.008640\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218716\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051114    G-Loss: -0.044017    Penlty:  0.007097\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202080\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052585    G-Loss: -0.043985    Penlty:  0.008600\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206297\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061783    G-Loss: -0.050673    Penlty:  0.011110\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.241906\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.046150    G-Loss: -0.042058    Penlty:  0.004092\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.179009\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.047923    G-Loss: -0.043527    Penlty:  0.004396\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.183597\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063801    G-Loss: -0.058949    Penlty:  0.004852\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.241276\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056548    G-Loss: -0.050022    Penlty:  0.006526\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218890\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050325    G-Loss: -0.043177    Penlty:  0.007148\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.195592\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053338    G-Loss: -0.048788    Penlty:  0.004550\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.207125\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062927    G-Loss: -0.054611    Penlty:  0.008316\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233113\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056567    G-Loss: -0.044132    Penlty:  0.012434\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226683\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054780    G-Loss: -0.043673    Penlty:  0.011107\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218183\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054096    G-Loss: -0.046281    Penlty:  0.007815\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206893\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065945    G-Loss: -0.056099    Penlty:  0.009847\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.249645\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064516    G-Loss: -0.057409    Penlty:  0.007107\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.245700\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059633    G-Loss: -0.048372    Penlty:  0.011261\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234533\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056612    G-Loss: -0.048784    Penlty:  0.007828\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223031\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062682    G-Loss: -0.054686    Penlty:  0.007996\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.243430\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.068618    G-Loss: -0.060608    Penlty:  0.008010\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.263151\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063817    G-Loss: -0.056715    Penlty:  0.007102\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242844\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064899    G-Loss: -0.053749    Penlty:  0.011150\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.249954\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052487    G-Loss: -0.043535    Penlty:  0.008953\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211704\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054316    G-Loss: -0.044415    Penlty:  0.009900\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217151\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056279    G-Loss: -0.051496    Penlty:  0.004783\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217210\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059979    G-Loss: -0.053155    Penlty:  0.006824\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.232364\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065616    G-Loss: -0.059685    Penlty:  0.005932\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.249329\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064743    G-Loss: -0.057625    Penlty:  0.007119\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.249060\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061346    G-Loss: -0.054288    Penlty:  0.007058\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236472\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051377    G-Loss: -0.046626    Penlty:  0.004751\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198491\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056222    G-Loss: -0.050810    Penlty:  0.005412\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217280\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052868    G-Loss: -0.046574    Penlty:  0.006293\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.204247\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063359    G-Loss: -0.055663    Penlty:  0.007696\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.244060\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051322    G-Loss: -0.044716    Penlty:  0.006605\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200472\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.071855    G-Loss: -0.062646    Penlty:  0.009210\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.267372\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053588    G-Loss: -0.046236    Penlty:  0.007352\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205335\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053311    G-Loss: -0.046226    Penlty:  0.007085\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205302\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056851    G-Loss: -0.051931    Penlty:  0.004920\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217857\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055919    G-Loss: -0.043726    Penlty:  0.012193\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227772\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061673    G-Loss: -0.050865    Penlty:  0.010808\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238021\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059175    G-Loss: -0.052157    Penlty:  0.007018\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226399\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056354    G-Loss: -0.048661    Penlty:  0.007693\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213496\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053870    G-Loss: -0.047585    Penlty:  0.006285\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210107\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049476    G-Loss: -0.044819    Penlty:  0.004656\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.191263\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062636    G-Loss: -0.052632    Penlty:  0.010004\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.240947\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056090    G-Loss: -0.048398    Penlty:  0.007692\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219134\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060954    G-Loss: -0.051493    Penlty:  0.009461\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233651\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064655    G-Loss: -0.059935    Penlty:  0.004720\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.241454\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.078378    G-Loss: -0.067443    Penlty:  0.010935\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.285860\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050450    G-Loss: -0.045223    Penlty:  0.005227\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.192551\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058308    G-Loss: -0.050863    Penlty:  0.007445\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223499\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053047    G-Loss: -0.048117    Penlty:  0.004930\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205803\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054793    G-Loss: -0.048518    Penlty:  0.006274\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213001\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062341    G-Loss: -0.055268    Penlty:  0.007073\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.239613\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055841    G-Loss: -0.049928    Penlty:  0.005913\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216494\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057300    G-Loss: -0.047330    Penlty:  0.009970\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222150\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056627    G-Loss: -0.049619    Penlty:  0.007008\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214045\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055233    G-Loss: -0.049717    Penlty:  0.005516\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212194\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054131    G-Loss: -0.046369    Penlty:  0.007761\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212083\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057347    G-Loss: -0.050736    Penlty:  0.006611\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221018\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055617    G-Loss: -0.049249    Penlty:  0.006368\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.208597\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061212    G-Loss: -0.054245    Penlty:  0.006967\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234867\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.069843    G-Loss: -0.061476    Penlty:  0.008367\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.262128\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055596    G-Loss: -0.047875    Penlty:  0.007721\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216372\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057740    G-Loss: -0.051045    Penlty:  0.006695\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222671\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050758    G-Loss: -0.045140    Penlty:  0.005618\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198240\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051168    G-Loss: -0.044779    Penlty:  0.006389\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.197868\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056969    G-Loss: -0.043476    Penlty:  0.013493\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231818\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058261    G-Loss: -0.051918    Penlty:  0.006344\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224357\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063665    G-Loss: -0.055370    Penlty:  0.008295\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.241225\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050545    G-Loss: -0.042681    Penlty:  0.007863\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.197300\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057209    G-Loss: -0.048820    Penlty:  0.008389\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218578\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059227    G-Loss: -0.052227    Penlty:  0.007001\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222993\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061908    G-Loss: -0.054329    Penlty:  0.007579\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238964\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057124    G-Loss: -0.045868    Penlty:  0.011256\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229736\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056787    G-Loss: -0.050974    Penlty:  0.005813\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218752\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059688    G-Loss: -0.051805    Penlty:  0.007884\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228016\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058491    G-Loss: -0.050497    Penlty:  0.007994\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222799\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062562    G-Loss: -0.055965    Penlty:  0.006597\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237513\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060329    G-Loss: -0.054403    Penlty:  0.005925\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228852\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055796    G-Loss: -0.048756    Penlty:  0.007041\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214366\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058668    G-Loss: -0.051869    Penlty:  0.006799\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226726\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052771    G-Loss: -0.048712    Penlty:  0.004059\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205845\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059508    G-Loss: -0.048739    Penlty:  0.010768\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231528\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053290    G-Loss: -0.047509    Penlty:  0.005780\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.207173\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057393    G-Loss: -0.052694    Penlty:  0.004699\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.220988\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050881    G-Loss: -0.046011    Penlty:  0.004869\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198267\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054431    G-Loss: -0.047486    Penlty:  0.006945\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205997\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063623    G-Loss: -0.054063    Penlty:  0.009559\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.243981\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056842    G-Loss: -0.049692    Penlty:  0.007150\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214771\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058292    G-Loss: -0.048918    Penlty:  0.009374\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221975\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054773    G-Loss: -0.048370    Penlty:  0.006403\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214206\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054430    G-Loss: -0.046251    Penlty:  0.008180\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211676\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055818    G-Loss: -0.049876    Penlty:  0.005942\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.220069\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055005    G-Loss: -0.049139    Penlty:  0.005866\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210935\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063545    G-Loss: -0.057890    Penlty:  0.005654\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236954\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063843    G-Loss: -0.055433    Penlty:  0.008410\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.244909\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050919    G-Loss: -0.044859    Penlty:  0.006059\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200700\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059510    G-Loss: -0.050324    Penlty:  0.009187\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231810\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061089    G-Loss: -0.051043    Penlty:  0.010046\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236829\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060622    G-Loss: -0.054429    Penlty:  0.006193\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233457\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060892    G-Loss: -0.051594    Penlty:  0.009298\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234902\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061142    G-Loss: -0.051516    Penlty:  0.009626\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.239168\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057400    G-Loss: -0.051846    Penlty:  0.005554\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.220312\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058641    G-Loss: -0.052642    Penlty:  0.005998\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228372\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056135    G-Loss: -0.049324    Penlty:  0.006811\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215384\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049641    G-Loss: -0.044715    Penlty:  0.004927\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.196121\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062788    G-Loss: -0.056617    Penlty:  0.006171\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238957\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056797    G-Loss: -0.051638    Penlty:  0.005159\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219004\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060694    G-Loss: -0.054971    Penlty:  0.005723\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233282\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.066068    G-Loss: -0.054777    Penlty:  0.011291\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.248707\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057559    G-Loss: -0.052062    Penlty:  0.005497\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215352\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059659    G-Loss: -0.052281    Penlty:  0.007378\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228374\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062942    G-Loss: -0.049105    Penlty:  0.013837\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242471\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058512    G-Loss: -0.053466    Penlty:  0.005047\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225817\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062135    G-Loss: -0.051803    Penlty:  0.010331\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234337\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055389    G-Loss: -0.047118    Penlty:  0.008270\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215733\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060040    G-Loss: -0.050589    Penlty:  0.009451\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.232596\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051806    G-Loss: -0.041850    Penlty:  0.009956\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210222\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051313    G-Loss: -0.043591    Penlty:  0.007722\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.199201\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050250    G-Loss: -0.045659    Penlty:  0.004591\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.191549\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054330    G-Loss: -0.045232    Penlty:  0.009098\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216817\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051670    G-Loss: -0.046420    Penlty:  0.005250\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198877\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058692    G-Loss: -0.052297    Penlty:  0.006395\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225250\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056197    G-Loss: -0.049709    Penlty:  0.006488\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217408\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055425    G-Loss: -0.049602    Penlty:  0.005823\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.209593\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055607    G-Loss: -0.047211    Penlty:  0.008396\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217949\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053145    G-Loss: -0.045498    Penlty:  0.007647\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206779\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052864    G-Loss: -0.047488    Penlty:  0.005375\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.204469\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054613    G-Loss: -0.047236    Penlty:  0.007377\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212215\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054118    G-Loss: -0.049146    Penlty:  0.004972\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211348\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.066239    G-Loss: -0.057785    Penlty:  0.008454\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.253017\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056271    G-Loss: -0.047610    Penlty:  0.008661\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216834\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.070441    G-Loss: -0.059489    Penlty:  0.010951\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.267545\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051606    G-Loss: -0.046139    Penlty:  0.005468\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200523\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049833    G-Loss: -0.042009    Penlty:  0.007824\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.199792\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056135    G-Loss: -0.048530    Penlty:  0.007605\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212287\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052717    G-Loss: -0.045056    Penlty:  0.007661\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.207377\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062231    G-Loss: -0.052088    Penlty:  0.010143\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238889\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056094    G-Loss: -0.049771    Penlty:  0.006324\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218794\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054921    G-Loss: -0.049202    Penlty:  0.005719\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.208294\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059001    G-Loss: -0.052950    Penlty:  0.006051\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225052\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056709    G-Loss: -0.045934    Penlty:  0.010775\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224800\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059740    G-Loss: -0.053152    Penlty:  0.006588\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229381\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056270    G-Loss: -0.049310    Penlty:  0.006960\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215238\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062145    G-Loss: -0.056488    Penlty:  0.005657\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238179\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061966    G-Loss: -0.053383    Penlty:  0.008583\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238643\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060372    G-Loss: -0.053286    Penlty:  0.007086\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228047\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060405    G-Loss: -0.054088    Penlty:  0.006317\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231500\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054255    G-Loss: -0.046339    Penlty:  0.007915\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210082\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057833    G-Loss: -0.049259    Penlty:  0.008574\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225021\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053444    G-Loss: -0.047029    Penlty:  0.006415\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.207512\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064781    G-Loss: -0.057965    Penlty:  0.006816\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.250545\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061337    G-Loss: -0.053948    Penlty:  0.007390\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236694\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051375    G-Loss: -0.044492    Penlty:  0.006883\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202150\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055517    G-Loss: -0.048133    Penlty:  0.007384\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215490\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053468    G-Loss: -0.047582    Penlty:  0.005885\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206511\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051411    G-Loss: -0.043861    Penlty:  0.007550\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.203675\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053703    G-Loss: -0.042998    Penlty:  0.010706\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213809\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048995    G-Loss: -0.038957    Penlty:  0.010039\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.201052\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057072    G-Loss: -0.048872    Penlty:  0.008200\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221721\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061661    G-Loss: -0.055148    Penlty:  0.006513\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234673\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060165    G-Loss: -0.051296    Penlty:  0.008869\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.232771\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065036    G-Loss: -0.057120    Penlty:  0.007916\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.244007\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054718    G-Loss: -0.049367    Penlty:  0.005350\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.209660\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053756    G-Loss: -0.048310    Penlty:  0.005446\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206198\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063441    G-Loss: -0.054733    Penlty:  0.008708\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.243686\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062409    G-Loss: -0.056150    Penlty:  0.006259\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238775\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057566    G-Loss: -0.049488    Penlty:  0.008078\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224716\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062779    G-Loss: -0.054519    Penlty:  0.008261\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.241946\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064592    G-Loss: -0.055944    Penlty:  0.008649\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.246844\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.066957    G-Loss: -0.054533    Penlty:  0.012424\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.257863\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058172    G-Loss: -0.050401    Penlty:  0.007771\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224466\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057452    G-Loss: -0.050099    Penlty:  0.007353\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223764\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053204    G-Loss: -0.047846    Penlty:  0.005358\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.207030\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055351    G-Loss: -0.050625    Penlty:  0.004726\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210469\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054519    G-Loss: -0.049135    Penlty:  0.005384\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210830\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.067282    G-Loss: -0.060048    Penlty:  0.007233\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.253874\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056768    G-Loss: -0.045952    Penlty:  0.010816\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224328\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063053    G-Loss: -0.051026    Penlty:  0.012027\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.246674\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051373    G-Loss: -0.043666    Penlty:  0.007707\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.203293\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061058    G-Loss: -0.054682    Penlty:  0.006376\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233893\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051436    G-Loss: -0.044598    Penlty:  0.006838\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200670\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054645    G-Loss: -0.049031    Penlty:  0.005614\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211659\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.069574    G-Loss: -0.062997    Penlty:  0.006577\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.262201\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052673    G-Loss: -0.042994    Penlty:  0.009679\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211826\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060696    G-Loss: -0.053038    Penlty:  0.007658\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231606\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050470    G-Loss: -0.043860    Penlty:  0.006611\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.194758\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056394    G-Loss: -0.050802    Penlty:  0.005592\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218518\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052835    G-Loss: -0.047356    Penlty:  0.005479\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.199545\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.070698    G-Loss: -0.062232    Penlty:  0.008465\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.263766\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054827    G-Loss: -0.048069    Penlty:  0.006758\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212254\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063497    G-Loss: -0.055940    Penlty:  0.007557\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.244012\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057982    G-Loss: -0.050325    Penlty:  0.007657\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223593\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048099    G-Loss: -0.040162    Penlty:  0.007937\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.194511\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063606    G-Loss: -0.055248    Penlty:  0.008358\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.241957\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049503    G-Loss: -0.041186    Penlty:  0.008318\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198288\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063578    G-Loss: -0.056520    Penlty:  0.007058\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234212\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058179    G-Loss: -0.050461    Penlty:  0.007718\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224753\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054102    G-Loss: -0.047957    Penlty:  0.006145\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.204564\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.066229    G-Loss: -0.057816    Penlty:  0.008414\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.254106\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056514    G-Loss: -0.047951    Penlty:  0.008563\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223049\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060191    G-Loss: -0.053803    Penlty:  0.006389\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228663\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051056    G-Loss: -0.045210    Penlty:  0.005846\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198244\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060032    G-Loss: -0.053797    Penlty:  0.006235\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229246\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051085    G-Loss: -0.043290    Penlty:  0.007795\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200499\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054787    G-Loss: -0.048780    Penlty:  0.006007\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211486\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051964    G-Loss: -0.044201    Penlty:  0.007763\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200840\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054176    G-Loss: -0.044258    Penlty:  0.009918\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217093\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054669    G-Loss: -0.049586    Penlty:  0.005083\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212020\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056420    G-Loss: -0.050775    Penlty:  0.005645\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219401\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052412    G-Loss: -0.045048    Penlty:  0.007364\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.204149\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060848    G-Loss: -0.049853    Penlty:  0.010995\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238868\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058115    G-Loss: -0.049773    Penlty:  0.008341\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224656\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059384    G-Loss: -0.052945    Penlty:  0.006439\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222520\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048098    G-Loss: -0.043609    Penlty:  0.004489\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.187620\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049764    G-Loss: -0.045470    Penlty:  0.004294\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.194912\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063102    G-Loss: -0.055128    Penlty:  0.007973\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242574\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064227    G-Loss: -0.056888    Penlty:  0.007339\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.247201\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051572    G-Loss: -0.047215    Penlty:  0.004357\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.201939\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049103    G-Loss: -0.041340    Penlty:  0.007763\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202195\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058403    G-Loss: -0.051425    Penlty:  0.006978\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224568\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054322    G-Loss: -0.048625    Penlty:  0.005697\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.208934\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052975    G-Loss: -0.046312    Penlty:  0.006663\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205740\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055215    G-Loss: -0.049908    Penlty:  0.005307\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213456\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059664    G-Loss: -0.053136    Penlty:  0.006527\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231282\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056781    G-Loss: -0.049977    Penlty:  0.006804\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218758\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065817    G-Loss: -0.057457    Penlty:  0.008359\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.252424\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056431    G-Loss: -0.046580    Penlty:  0.009852\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224273\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050816    G-Loss: -0.044181    Penlty:  0.006634\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.197500\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050720    G-Loss: -0.044416    Penlty:  0.006303\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.199834\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052776    G-Loss: -0.047770    Penlty:  0.005007\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.204077\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.066111    G-Loss: -0.058437    Penlty:  0.007674\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.248099\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058741    G-Loss: -0.051903    Penlty:  0.006838\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223080\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053284    G-Loss: -0.046798    Penlty:  0.006486\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.203833\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048810    G-Loss: -0.044599    Penlty:  0.004211\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.187618\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059323    G-Loss: -0.053762    Penlty:  0.005562\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227380\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060073    G-Loss: -0.047348    Penlty:  0.012726\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.239743\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053294    G-Loss: -0.043163    Penlty:  0.010131\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212640\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058342    G-Loss: -0.051169    Penlty:  0.007174\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224023\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055356    G-Loss: -0.047343    Penlty:  0.008013\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212065\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060589    G-Loss: -0.052916    Penlty:  0.007673\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.230079\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065597    G-Loss: -0.059374    Penlty:  0.006223\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.241345\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060243    G-Loss: -0.051720    Penlty:  0.008524\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231390\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064080    G-Loss: -0.055146    Penlty:  0.008934\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.245595\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048488    G-Loss: -0.042403    Penlty:  0.006085\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.191803\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055407    G-Loss: -0.047678    Penlty:  0.007729\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216006\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048232    G-Loss: -0.041461    Penlty:  0.006771\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.192558\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051648    G-Loss: -0.040368    Penlty:  0.011280\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215204\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058461    G-Loss: -0.049459    Penlty:  0.009003\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224666\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058599    G-Loss: -0.050871    Penlty:  0.007728\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228154\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057279    G-Loss: -0.045792    Penlty:  0.011486\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227212\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062514    G-Loss: -0.052384    Penlty:  0.010130\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237899\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050700    G-Loss: -0.044609    Penlty:  0.006091\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.197367\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059000    G-Loss: -0.051882    Penlty:  0.007118\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227071\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057279    G-Loss: -0.048836    Penlty:  0.008443\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221953\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058354    G-Loss: -0.049185    Penlty:  0.009169\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228675\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050590    G-Loss: -0.043482    Penlty:  0.007108\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198208\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053874    G-Loss: -0.047863    Penlty:  0.006011\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.209731\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052820    G-Loss: -0.046061    Penlty:  0.006759\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206619\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055193    G-Loss: -0.048022    Penlty:  0.007171\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216056\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051446    G-Loss: -0.041815    Penlty:  0.009631\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206444\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058092    G-Loss: -0.046554    Penlty:  0.011539\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227352\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051747    G-Loss: -0.044666    Penlty:  0.007081\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200720\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064767    G-Loss: -0.052329    Penlty:  0.012438\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.255260\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062024    G-Loss: -0.054025    Penlty:  0.007998\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236952\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060432    G-Loss: -0.054554    Penlty:  0.005878\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233658\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055040    G-Loss: -0.044585    Penlty:  0.010455\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216330\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058481    G-Loss: -0.047997    Penlty:  0.010484\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229150\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065046    G-Loss: -0.057192    Penlty:  0.007854\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.247449\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052562    G-Loss: -0.045702    Penlty:  0.006860\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205289\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050712    G-Loss: -0.045336    Penlty:  0.005377\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198848\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.067581    G-Loss: -0.053613    Penlty:  0.013968\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.259816\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055934    G-Loss: -0.045562    Penlty:  0.010372\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217485\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054262    G-Loss: -0.048968    Penlty:  0.005294\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.207728\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055170    G-Loss: -0.049246    Penlty:  0.005924\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215357\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052936    G-Loss: -0.045658    Penlty:  0.007277\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205553\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052202    G-Loss: -0.044433    Penlty:  0.007769\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200002\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057934    G-Loss: -0.049150    Penlty:  0.008784\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224956\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050484    G-Loss: -0.045952    Penlty:  0.004532\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.194011\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054928    G-Loss: -0.050047    Penlty:  0.004881\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211812\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057282    G-Loss: -0.047640    Penlty:  0.009642\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226796\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054756    G-Loss: -0.048076    Penlty:  0.006680\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.208962\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054337    G-Loss: -0.047670    Penlty:  0.006666\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211004\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.067847    G-Loss: -0.058759    Penlty:  0.009088\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.256883\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055572    G-Loss: -0.046566    Penlty:  0.009005\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212907\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053000    G-Loss: -0.047958    Penlty:  0.005042\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.203753\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054112    G-Loss: -0.050231    Penlty:  0.003881\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.209778\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057896    G-Loss: -0.047164    Penlty:  0.010732\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227957\n",
      "\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.068127    G-Loss: -0.060227    Penlty:  0.007900\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.262445\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062513    G-Loss: -0.051540    Penlty:  0.010973\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242239\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057572    G-Loss: -0.051507    Penlty:  0.006065\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222750\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062958    G-Loss: -0.055806    Penlty:  0.007151\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233567\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056000    G-Loss: -0.049813    Penlty:  0.006187\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214687\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053854    G-Loss: -0.045218    Penlty:  0.008636\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215256\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055038    G-Loss: -0.048748    Penlty:  0.006290\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211490\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057834    G-Loss: -0.049251    Penlty:  0.008583\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223684\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061758    G-Loss: -0.053008    Penlty:  0.008750\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237177\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055317    G-Loss: -0.048946    Penlty:  0.006371\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212563\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055217    G-Loss: -0.048942    Penlty:  0.006274\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211298\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057597    G-Loss: -0.049820    Penlty:  0.007777\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219981\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057734    G-Loss: -0.051327    Penlty:  0.006407\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219474\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.046916    G-Loss: -0.038195    Penlty:  0.008722\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.191689\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057904    G-Loss: -0.045810    Penlty:  0.012094\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231460\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052278    G-Loss: -0.043692    Penlty:  0.008586\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.208995\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056094    G-Loss: -0.048419    Penlty:  0.007675\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216729\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058990    G-Loss: -0.049182    Penlty:  0.009808\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229457\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057547    G-Loss: -0.052809    Penlty:  0.004738\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219566\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052600    G-Loss: -0.043669    Penlty:  0.008932\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206271\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053427    G-Loss: -0.047567    Penlty:  0.005860\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205921\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061465    G-Loss: -0.055974    Penlty:  0.005491\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234081\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056258    G-Loss: -0.051390    Penlty:  0.004868\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217579\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048203    G-Loss: -0.043406    Penlty:  0.004797\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.186713\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059032    G-Loss: -0.052194    Penlty:  0.006838\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228080\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048561    G-Loss: -0.043559    Penlty:  0.005001\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.189976\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054508    G-Loss: -0.047118    Penlty:  0.007390\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212282\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057719    G-Loss: -0.051221    Penlty:  0.006498\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221198\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050094    G-Loss: -0.044302    Penlty:  0.005791\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.196167\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061825    G-Loss: -0.053996    Penlty:  0.007829\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238285\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058693    G-Loss: -0.049968    Penlty:  0.008725\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225332\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058716    G-Loss: -0.051881    Penlty:  0.006835\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222574\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050023    G-Loss: -0.042276    Penlty:  0.007748\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.198492\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062278    G-Loss: -0.056234    Penlty:  0.006044\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.239437\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057485    G-Loss: -0.052038    Penlty:  0.005446\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219271\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057651    G-Loss: -0.052636    Penlty:  0.005015\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223972\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065638    G-Loss: -0.058471    Penlty:  0.007167\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.249794\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058285    G-Loss: -0.049045    Penlty:  0.009239\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227086\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058886    G-Loss: -0.051533    Penlty:  0.007354\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228129\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060403    G-Loss: -0.052417    Penlty:  0.007986\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.232516\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060243    G-Loss: -0.051993    Penlty:  0.008250\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231415\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048551    G-Loss: -0.043249    Penlty:  0.005302\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.190437\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055717    G-Loss: -0.046813    Penlty:  0.008904\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216375\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059941    G-Loss: -0.047314    Penlty:  0.012627\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237665\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055722    G-Loss: -0.048082    Penlty:  0.007640\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214516\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052888    G-Loss: -0.040182    Penlty:  0.012707\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219851\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056507    G-Loss: -0.046232    Penlty:  0.010276\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223306\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056854    G-Loss: -0.049949    Penlty:  0.006905\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.220581\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061816    G-Loss: -0.053203    Penlty:  0.008613\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219196\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051728    G-Loss: -0.045553    Penlty:  0.006175\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.201831\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051359    G-Loss: -0.044058    Penlty:  0.007301\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202990\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056015    G-Loss: -0.049149    Penlty:  0.006866\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217339\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052836    G-Loss: -0.046564    Penlty:  0.006272\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.201292\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051574    G-Loss: -0.047195    Penlty:  0.004379\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.199870\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063672    G-Loss: -0.055645    Penlty:  0.008027\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.245748\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059649    G-Loss: -0.051816    Penlty:  0.007833\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221483\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048602    G-Loss: -0.043788    Penlty:  0.004813\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.184708\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057725    G-Loss: -0.049993    Penlty:  0.007732\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224154\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051137    G-Loss: -0.046587    Penlty:  0.004550\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.196660\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056883    G-Loss: -0.050819    Penlty:  0.006064\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221719\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.074598    G-Loss: -0.062303    Penlty:  0.012295\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.285174\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057782    G-Loss: -0.050180    Penlty:  0.007602\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221117\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054856    G-Loss: -0.050018    Penlty:  0.004839\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.209070\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058323    G-Loss: -0.053379    Penlty:  0.004944\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225216\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052165    G-Loss: -0.045895    Penlty:  0.006270\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.203646\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054753    G-Loss: -0.047252    Penlty:  0.007501\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210434\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056541    G-Loss: -0.051283    Penlty:  0.005257\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218447\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052419    G-Loss: -0.047086    Penlty:  0.005334\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.204044\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051583    G-Loss: -0.046960    Penlty:  0.004623\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.201139\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062372    G-Loss: -0.051149    Penlty:  0.011222\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.246499\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056644    G-Loss: -0.051180    Penlty:  0.005464\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217591\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048332    G-Loss: -0.044868    Penlty:  0.003464\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.189286\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060776    G-Loss: -0.053788    Penlty:  0.006988\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.232412\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059139    G-Loss: -0.047911    Penlty:  0.011228\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.232725\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054182    G-Loss: -0.049207    Penlty:  0.004975\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212117\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059053    G-Loss: -0.049774    Penlty:  0.009279\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229400\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058915    G-Loss: -0.054644    Penlty:  0.004271\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225750\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055451    G-Loss: -0.050283    Penlty:  0.005168\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213843\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056703    G-Loss: -0.050210    Penlty:  0.006494\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213214\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053740    G-Loss: -0.048093    Penlty:  0.005647\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205066\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061566    G-Loss: -0.054941    Penlty:  0.006624\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.235141\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063747    G-Loss: -0.057034    Penlty:  0.006713\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242857\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057065    G-Loss: -0.048378    Penlty:  0.008687\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222702\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057677    G-Loss: -0.049822    Penlty:  0.007855\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223673\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065162    G-Loss: -0.058126    Penlty:  0.007037\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.247797\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054645    G-Loss: -0.046691    Penlty:  0.007954\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212306\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051010    G-Loss: -0.044825    Penlty:  0.006185\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.199342\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062271    G-Loss: -0.057415    Penlty:  0.004856\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238026\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049661    G-Loss: -0.040546    Penlty:  0.009115\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200367\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054763    G-Loss: -0.046961    Penlty:  0.007802\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211855\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050953    G-Loss: -0.044299    Penlty:  0.006654\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.196728\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051676    G-Loss: -0.044269    Penlty:  0.007407\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.201830\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052897    G-Loss: -0.043470    Penlty:  0.009427\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.208637\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059080    G-Loss: -0.053097    Penlty:  0.005984\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227180\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.067934    G-Loss: -0.061060    Penlty:  0.006874\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.258296\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055378    G-Loss: -0.049992    Penlty:  0.005386\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213682\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061395    G-Loss: -0.055429    Penlty:  0.005967\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233415\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.047297    G-Loss: -0.040905    Penlty:  0.006392\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.190673\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056897    G-Loss: -0.051163    Penlty:  0.005733\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218597\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059120    G-Loss: -0.052123    Penlty:  0.006997\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228695\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058785    G-Loss: -0.051115    Penlty:  0.007670\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224086\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049071    G-Loss: -0.044838    Penlty:  0.004234\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.189716\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054955    G-Loss: -0.047391    Penlty:  0.007565\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213304\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.073360    G-Loss: -0.059836    Penlty:  0.013524\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.277190\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052429    G-Loss: -0.044359    Penlty:  0.008070\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206295\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062576    G-Loss: -0.053676    Penlty:  0.008900\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.239395\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057626    G-Loss: -0.051677    Penlty:  0.005949\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222051\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053420    G-Loss: -0.047107    Penlty:  0.006313\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206108\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056011    G-Loss: -0.050391    Penlty:  0.005620\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216149\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063775    G-Loss: -0.055020    Penlty:  0.008755\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.239523\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059687    G-Loss: -0.052064    Penlty:  0.007623\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229186\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057796    G-Loss: -0.050412    Penlty:  0.007384\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221866\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050990    G-Loss: -0.043837    Penlty:  0.007153\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.199784\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056744    G-Loss: -0.050718    Penlty:  0.006026\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218753\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065874    G-Loss: -0.056011    Penlty:  0.009863\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.251391\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.047443    G-Loss: -0.036726    Penlty:  0.010717\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.195929\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055791    G-Loss: -0.050988    Penlty:  0.004803\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214107\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055490    G-Loss: -0.044979    Penlty:  0.010511\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221292\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051479    G-Loss: -0.044163    Penlty:  0.007316\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.203177\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061782    G-Loss: -0.057244    Penlty:  0.004538\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234715\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058882    G-Loss: -0.047220    Penlty:  0.011662\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.230974\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065296    G-Loss: -0.057008    Penlty:  0.008288\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242943\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060358    G-Loss: -0.054434    Penlty:  0.005924\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.232181\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059951    G-Loss: -0.052259    Penlty:  0.007692\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.227478\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056550    G-Loss: -0.051044    Penlty:  0.005506\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219887\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052410    G-Loss: -0.046844    Penlty:  0.005567\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.203479\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052658    G-Loss: -0.046231    Penlty:  0.006427\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206071\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055201    G-Loss: -0.048327    Penlty:  0.006874\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217066\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057380    G-Loss: -0.047872    Penlty:  0.009508\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224899\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052476    G-Loss: -0.042378    Penlty:  0.010097\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.209120\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056747    G-Loss: -0.051333    Penlty:  0.005415\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218885\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058964    G-Loss: -0.051934    Penlty:  0.007031\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226618\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054024    G-Loss: -0.045939    Penlty:  0.008085\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.207889\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063591    G-Loss: -0.054019    Penlty:  0.009573\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.244682\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057774    G-Loss: -0.049927    Penlty:  0.007846\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.220016\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061459    G-Loss: -0.055384    Penlty:  0.006075\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237533\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062382    G-Loss: -0.053787    Penlty:  0.008595\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.239009\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.048436    G-Loss: -0.041341    Penlty:  0.007095\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.190898\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058449    G-Loss: -0.052169    Penlty:  0.006279\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224737\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053502    G-Loss: -0.043421    Penlty:  0.010081\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211796\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061849    G-Loss: -0.050879    Penlty:  0.010970\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242400\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051543    G-Loss: -0.040329    Penlty:  0.011214\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213466\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058308    G-Loss: -0.050805    Penlty:  0.007503\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226767\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065909    G-Loss: -0.057057    Penlty:  0.008851\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.230985\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.067582    G-Loss: -0.056549    Penlty:  0.011033\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.250912\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055275    G-Loss: -0.048369    Penlty:  0.006907\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210835\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060796    G-Loss: -0.053752    Penlty:  0.007044\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.234281\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049300    G-Loss: -0.040871    Penlty:  0.008430\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.194533\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051310    G-Loss: -0.044387    Penlty:  0.006924\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.201825\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057205    G-Loss: -0.049124    Penlty:  0.008081\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224578\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051222    G-Loss: -0.043582    Penlty:  0.007640\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.203585\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053244    G-Loss: -0.046368    Penlty:  0.006875\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.207647\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058381    G-Loss: -0.052864    Penlty:  0.005518\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223199\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059540    G-Loss: -0.053719    Penlty:  0.005821\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226527\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054629    G-Loss: -0.042628    Penlty:  0.012002\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223211\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059031    G-Loss: -0.052246    Penlty:  0.006785\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228452\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056570    G-Loss: -0.049346    Penlty:  0.007224\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218945\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063130    G-Loss: -0.054092    Penlty:  0.009038\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.241320\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064522    G-Loss: -0.056547    Penlty:  0.007974\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242036\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058914    G-Loss: -0.050869    Penlty:  0.008045\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225596\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057350    G-Loss: -0.048828    Penlty:  0.008523\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222645\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056668    G-Loss: -0.050199    Penlty:  0.006469\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219101\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057350    G-Loss: -0.049019    Penlty:  0.008331\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224636\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057689    G-Loss: -0.051231    Penlty:  0.006458\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223838\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055436    G-Loss: -0.051087    Penlty:  0.004349\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214918\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057029    G-Loss: -0.052645    Penlty:  0.004384\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218507\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062413    G-Loss: -0.050828    Penlty:  0.011585\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.244616\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.065027    G-Loss: -0.060342    Penlty:  0.004685\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.249138\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061588    G-Loss: -0.051949    Penlty:  0.009639\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.235455\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052090    G-Loss: -0.045422    Penlty:  0.006668\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202082\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055856    G-Loss: -0.052078    Penlty:  0.003778\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215785\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062161    G-Loss: -0.055655    Penlty:  0.006507\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237207\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052503    G-Loss: -0.045781    Penlty:  0.006722\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205759\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056910    G-Loss: -0.049538    Penlty:  0.007372\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221185\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056108    G-Loss: -0.050533    Penlty:  0.005576\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213541\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062523    G-Loss: -0.051586    Penlty:  0.010937\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237720\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062214    G-Loss: -0.052482    Penlty:  0.009732\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.240092\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054661    G-Loss: -0.045278    Penlty:  0.009383\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217712\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064316    G-Loss: -0.054612    Penlty:  0.009705\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.247081\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056709    G-Loss: -0.049209    Penlty:  0.007500\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221726\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058104    G-Loss: -0.050628    Penlty:  0.007476\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226688\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054359    G-Loss: -0.047778    Penlty:  0.006581\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.206079\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056041    G-Loss: -0.048475    Penlty:  0.007565\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210016\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060180    G-Loss: -0.051157    Penlty:  0.009023\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.230683\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.047924    G-Loss: -0.040713    Penlty:  0.007211\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.191432\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063968    G-Loss: -0.054344    Penlty:  0.009624\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.243149\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055176    G-Loss: -0.046287    Penlty:  0.008889\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217202\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051981    G-Loss: -0.043731    Penlty:  0.008250\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.205735\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051208    G-Loss: -0.040283    Penlty:  0.010925\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.214765\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056334    G-Loss: -0.049161    Penlty:  0.007173\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216633\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058087    G-Loss: -0.047971    Penlty:  0.010116\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223223\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061952    G-Loss: -0.057272    Penlty:  0.004680\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237198\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053603    G-Loss: -0.044841    Penlty:  0.008762\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.209751\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050614    G-Loss: -0.045050    Penlty:  0.005564\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.197232\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057487    G-Loss: -0.048926    Penlty:  0.008561\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224807\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056814    G-Loss: -0.052135    Penlty:  0.004679\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.219381\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057089    G-Loss: -0.049362    Penlty:  0.007727\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.222621\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053748    G-Loss: -0.044037    Penlty:  0.009711\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218019\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056387    G-Loss: -0.050091    Penlty:  0.006296\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218839\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060230    G-Loss: -0.054266    Penlty:  0.005963\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228950\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059286    G-Loss: -0.051197    Penlty:  0.008089\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.228877\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061745    G-Loss: -0.054458    Penlty:  0.007288\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.235502\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055021    G-Loss: -0.049733    Penlty:  0.005288\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216481\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056385    G-Loss: -0.050368    Penlty:  0.006017\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.211974\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059384    G-Loss: -0.048155    Penlty:  0.011229\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.232245\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059197    G-Loss: -0.051765    Penlty:  0.007431\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225956\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061382    G-Loss: -0.052920    Penlty:  0.008461\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236977\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059341    G-Loss: -0.050648    Penlty:  0.008693\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.229939\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058838    G-Loss: -0.051501    Penlty:  0.007337\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226802\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058194    G-Loss: -0.049979    Penlty:  0.008214\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224552\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058064    G-Loss: -0.051087    Penlty:  0.006976\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221209\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060639    G-Loss: -0.053498    Penlty:  0.007141\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233211\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061528    G-Loss: -0.054194    Penlty:  0.007334\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236189\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060587    G-Loss: -0.049380    Penlty:  0.011207\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.238700\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.060032    G-Loss: -0.052306    Penlty:  0.007726\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233103\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063559    G-Loss: -0.056686    Penlty:  0.006873\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.243045\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053931    G-Loss: -0.047215    Penlty:  0.006716\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.209944\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057294    G-Loss: -0.051190    Penlty:  0.006103\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.221334\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062721    G-Loss: -0.056059    Penlty:  0.006662\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.240987\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062457    G-Loss: -0.052621    Penlty:  0.009836\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.239903\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059023    G-Loss: -0.053892    Penlty:  0.005131\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.226456\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.068303    G-Loss: -0.060370    Penlty:  0.007933\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.253086\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064584    G-Loss: -0.054854    Penlty:  0.009730\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.249785\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057766    G-Loss: -0.049588    Penlty:  0.008178\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.224971\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061266    G-Loss: -0.052781    Penlty:  0.008485\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.233874\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052299    G-Loss: -0.046637    Penlty:  0.005663\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202307\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063587    G-Loss: -0.054545    Penlty:  0.009042\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.241663\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052469    G-Loss: -0.046882    Penlty:  0.005587\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.202520\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.064484    G-Loss: -0.058063    Penlty:  0.006420\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.240528\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053060    G-Loss: -0.043219    Penlty:  0.009841\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213987\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059862    G-Loss: -0.052096    Penlty:  0.007766\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225855\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056031    G-Loss: -0.048085    Penlty:  0.007946\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.217859\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056861    G-Loss: -0.051810    Penlty:  0.005051\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216956\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.066147    G-Loss: -0.055325    Penlty:  0.010822\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.255560\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057859    G-Loss: -0.049799    Penlty:  0.008059\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223123\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062671    G-Loss: -0.051760    Penlty:  0.010911\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.242316\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057534    G-Loss: -0.046806    Penlty:  0.010727\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.223443\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050297    G-Loss: -0.041832    Penlty:  0.008464\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.200872\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.049393    G-Loss: -0.042998    Penlty:  0.006395\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.192857\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054350    G-Loss: -0.046482    Penlty:  0.007867\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212918\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.059379    G-Loss: -0.051610    Penlty:  0.007769\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.230206\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.050514    G-Loss: -0.043410    Penlty:  0.007103\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.196936\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061379    G-Loss: -0.054015    Penlty:  0.007365\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237208\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054538    G-Loss: -0.049466    Penlty:  0.005071\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.208841\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055131    G-Loss: -0.048545    Penlty:  0.006586\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.213966\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052306    G-Loss: -0.042125    Penlty:  0.010181\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.207885\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.068482    G-Loss: -0.060128    Penlty:  0.008354\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.253751\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055702    G-Loss: -0.050610    Penlty:  0.005092\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210976\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055205    G-Loss: -0.047733    Penlty:  0.007473\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215052\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056109    G-Loss: -0.049361    Penlty:  0.006747\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.212894\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056564    G-Loss: -0.051079    Penlty:  0.005485\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.218212\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.053020    G-Loss: -0.043528    Penlty:  0.009493\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.209838\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.055505    G-Loss: -0.047643    Penlty:  0.007862\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.216256\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.063181    G-Loss: -0.056505    Penlty:  0.006677\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.239650\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.052573    G-Loss: -0.041699    Penlty:  0.010875\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215830\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.062659    G-Loss: -0.057793    Penlty:  0.004866\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.237875\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.051514    G-Loss: -0.045833    Penlty:  0.005681\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.199714\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.054773    G-Loss: -0.049727    Penlty:  0.005046\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.210868\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.056771    G-Loss: -0.050133    Penlty:  0.006638\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.220397\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058203    G-Loss: -0.050884    Penlty:  0.007319\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.225090\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.061177    G-Loss: -0.050699    Penlty:  0.010478\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.236936\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.066337    G-Loss: -0.054913    Penlty:  0.011424\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.256128\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.057094    G-Loss: -0.052349    Penlty:  0.004746\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.215285\n",
      "\n",
      "Iter: 1  \tH-Loss:  0.058494    G-Loss: -0.048573    Penlty:  0.009920\n",
      "Iter: 1   \tdrift:  0.000000    sigma:  0.231404\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, rh_gan in tqdm(enumerate(robust_dh_gans), total=number_of_scenarios):\n",
    "    try:\n",
    "        rh_gan.hedge_config.deep_hedge.load_state_dict(torch.load(f'resources/network-states/bs_test/gan_scenario_{i}.pt'))\n",
    "    except FileNotFoundError:\n",
    "        rh_gan.hedge_config.deep_hedge.train()\n",
    "        rh_gan.gen_config.generator.train()\n",
    "        rh_gan.activate_generation_training()\n",
    "        rh_gan.activate_hedge_training()\n",
    "        rh_gan.fit(1, callbacks=[PrintMetrics(), PrintGeneratorParameters(), PrintEmptyLine()])\n",
    "        torch.save(rh_gan.hedge_config.deep_hedge.state_dict(), f'resources/network-states/bs_test/gan_scenario_{i}.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf8826-0f8e-4b51-9332-bc2cbc2940d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, dh in enumerate(deep_hedges):\n",
    "#     torch.save(dh.state_dict(), f'resources/network-states/bs_test/gan_scenario_{i}.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6f665163-bbbe-4d6e-95c2-2af98a2798cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b65d137b6046bfa3aec207e97a83e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oosp_robust = [hedge_objective(dh(test_data)).item() for dh in tqdm(deep_hedges)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f084dff-a952-42ff-834d-d767a992e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_bins = 100\n",
    "plt.hist(oosp, bins=no_bins)\n",
    "plt.hist(oosp_robust, bins=no_bins)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "94d9e167-64f3-4f72-8f1b-0631c0260aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (10, 4))\n",
    "\n",
    "vals_n, bins = np.histogram(oosp, bins=40)\n",
    "vals_r = np.histogram(oosp_robust, bins=bins)[0]\n",
    "bin_centers = 0.5*(bins[1:]+bins[:-1])\n",
    "axs[0].hist(oosp, bins=bins, label='deep hedge', color='C0', alpha=.7)\n",
    "axs[0].hist(oosp_robust, bins=bins, label='robust hedge GAN', color='C1', alpha=.7)\n",
    "axs[0].set_xlabel('Out-of-sample Performance')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].legend()\n",
    "# axs[0].set_title('')\n",
    "\n",
    "axs[1].scatter([bs_parameters.sigma - v for v in volatilities_for_scenarios], oosp, label='deep hedge', s=2)\n",
    "axs[1].scatter([bs_parameters.sigma - v for v in volatilities_for_scenarios], oosp_robust, label='robust hedge GAN', s=2)\n",
    "axs[1].set_xlabel('Sigma Calibration Error')\n",
    "axs[1].set_ylabel('Out-of-sample Performance')\n",
    "axs[1].legend()\n",
    "# axs[1].set_title()\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figs/BlackScholesRobustification.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c1fafbe3-638d-40e3-acfc-e2017459ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive:   0.0521750201433897\n",
      "Robust:  0.052086425226181746\n",
      "\n",
      "Naive:   0.0007295896779737821\n",
      "Robust:  0.0005935807837077448\n"
     ]
    }
   ],
   "source": [
    "print('Naive:  ', np.mean(oosp))\n",
    "print('Robust: ', np.mean(oosp_robust))\n",
    "print()\n",
    "print('Naive:  ', np.std(oosp))\n",
    "print('Robust: ', np.std(oosp_robust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d32059d7-9937-4dbc-ac05-e55bea4c23a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135816632661779"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(oosp_robust)/np.std(oosp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41010093-b3aa-443d-ac81-4e826dd1d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(dh.state_dict(), 'resources/network-states/deep_hedge_for_heston.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c61f64-2b79-4020-865d-98d473018412",
   "metadata": {},
   "source": [
    "### Loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6debbfa-4a09-49c3-ada3-0905fe80968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12add580-86d4-46a7-b1b6-eb8345785b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_config = BlackScholesCoefficientConfig(\n",
    "    BlackScholesParameterSet(drift=bs_parameters.drift, sigma=volatilities_for_scenarios[i]),\n",
    "    initial_asset_price=1.0,\n",
    ")\n",
    "drift_coef, diffusion_coef = BlackScholesDriftCoefficient(coef_config), BlackScholesDiffusionCoefficient(coef_config)\n",
    "gen_config = GeneratorConfig(td, drift_coef.get_initial_asset_price, drift_coef, diffusion_coef)\n",
    "g = SdeGenerator(generator_config=gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f01fad-01e7-4d92-8faa-b4a2a77453eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_config = StrategyNetConfig(dimension_of_asset=1, number_of_layers=3, nodes_in_intermediate_layers=36)\n",
    "initial_asset_price_for_deep_hedge = torch.tensor([initial_asset_price], dtype=torch.float32)\n",
    "dh = DeepHedge(DeepHedgeConfig(derivative, initial_asset_price_for_deep_hedge, strategy_config))\n",
    "dh.load_state_dict(torch.load(f'resources/network-states/bs_test/scenario_{i}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce92a53-a02e-4a0d-8805-8f20871ce5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_opt = torch.optim.Adam(g.parameters())\n",
    "gen_adapters = AdapterList([])\n",
    "gen_train_config = SdeGeneratorTrainerConfig(g, penalizers[i], g_opt, gen_adapters)\n",
    "\n",
    "h_opt = torch.optim.Adam(dh.parameters())\n",
    "hedge_adapters = AdapterList([ConvertToIncrements()])\n",
    "dh_train_config = DeepHedgeTrainerConfig(dh, hedge_objective, h_opt, hedge_adapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb350ca0-86b2-4796-b9c4-032f001061cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [noise_generator(1000) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2998de-51bd-45be-9837-35c104f74c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_losses = QuantityLogger()\n",
    "g_losses = QuantityLogger()\n",
    "p_losses = QuantityLogger()\n",
    "\n",
    "for batch in batches:\n",
    "    generated = g(batch)\n",
    "    profit_and_loss = dh(dh_train_config.generation_adapters(generated))\n",
    "    hedge_loss = hedge_objective(profit_and_loss)\n",
    "    dh.zero_grad()\n",
    "    hedge_loss.backward()\n",
    "    dh_train_config.optimizer.step()\n",
    "    dh_train_config.scheduler.step()\n",
    "    h_losses.update(hedge_loss.item())\n",
    "    \n",
    "    generated = g(batch)\n",
    "    profit_and_loss = dh(dh_train_config.generation_adapters(generated))\n",
    "    hedge_loss = hedge_objective(profit_and_loss)\n",
    "    penalty = penalizers[i](gen_train_config.penalization_adapters(generated))\n",
    "    generation_loss = penalty - hedge_loss\n",
    "    g.zero_grad()\n",
    "    generation_loss.backward()\n",
    "    gen_train_config.optimizer.step()\n",
    "    gen_train_config.scheduler.step()\n",
    "    g_losses.update(generation_loss.item())\n",
    "    p_losses.update(penalty.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf7b913-2dd2-49f5-a10e-064568b7c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpl_axes_aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7969a233-8ed4-45c0-b956-e8936c0ccf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (10, 4))\n",
    "\n",
    "axs[0].plot(np.load('resources/network-states/bs_test/losses.npz', allow_pickle=True)['scenario_0'], label='Hedge Loss')\n",
    "axs[0].set_xlabel('Iterations')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend()\n",
    "# axs[0].set_title()\n",
    "\n",
    "axs[1].plot(h_losses.history, c='C0', label='Hedge Loss')\n",
    "axs[1].set_xlabel('Iterations')\n",
    "axs[1].set_ylabel('Loss')\n",
    "# axs[1].set_title('')\n",
    "\n",
    "axs_clone = axs[1].twinx()\n",
    "axs_clone.plot(g_losses.history, c='C1', label='Generation Loss')\n",
    "axs[1].legend()\n",
    "axs_clone.legend(loc='lower left')\n",
    "\n",
    "axs_clone.grid(False)\n",
    "\n",
    "mpl_axes_aligner.align.yaxes(axs[1], h_losses.history[0], axs_clone, g_losses.history[0])\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figs/BlackScholesLossCurves.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fdfd70-453d-4c61-9428-539012a6f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g_losses.history[0])\n",
    "print(h_losses.history[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c60ab-bfd3-4159-ba13-721ac166d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.load_state_dict(torch.load('resources/network-states/deep_hedge_for_heston.pt'))\n",
    "robust_dh_gan.hedge_config.reset_scheduler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc8a7d7-4655-4984-9d6f-053b7f7798b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.diff(heston_generator(5000), 1, 1)[:, :, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd20500-3e41-4866-9c42-316cb30a10ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.eval()\n",
    "n_res = np.sum(dh(inputs).detach().numpy() * inputs.numpy(), axis=(1, 2))\n",
    "term_a_v = np.sum(inputs.numpy(), axis=1)[:, 0] + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf779a-3383-44ae-b8f4-5fec9cb8fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(term_a_v, n_res, s=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988360cb-31e9-4ad3-9e2f-4f44e2473ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not necessary, we start with the optimal initialization.\n",
    "# robust_dh_gan.deactivate_hedge_training()\n",
    "# robust_dh_gan.fit(5, callbacks=[PrintHestonParameters()])\n",
    "# robust_dh_gan.activate_hedge_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f6d8e-7b0d-42e2-9175-ce13e9cf07c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.train()\n",
    "generator.train()\n",
    "robust_dh_gan.activate_generation_training()\n",
    "robust_dh_gan.fit(100, callbacks=[PrintMetrics()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2afabe-3d39-4064-997e-08caba34f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.eval()\n",
    "r_res = np.sum(dh(inputs).detach().numpy() * inputs.numpy(), axis=(1, 2))\n",
    "term_a_v = np.sum(inputs.numpy(), axis=1)[:, 0] + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de31bf9-abf8-4257-8b70-90511a40cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(term_a_v, r_res, s=.1)\n",
    "plt.scatter(term_a_v, n_res, s=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a38f42-d7c1-4f9d-acac-0d47169432b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(term_a_v, r_res - n_res, s=.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARDH",
   "language": "python",
   "name": "ardh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
